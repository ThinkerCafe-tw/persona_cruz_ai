```markdown
# 🌱🔥 02. 高級記憶模組設計 (V1)：基於 RAG 擴展

**主導人格**: 🌱 木 (產品經理), 🔥 火 (開發專員)
**協作人格**: 🏔️ 土 (架構師), 💧 水 (測試專員)

為 AI 助手建立長期、個性化、跨對話的記憶能力，是我們「個性化 AI 助手計畫」的核心目標和主要差異化優勢。本文件旨在分析 LibreChat 現有 RAG 架構作為記憶基礎的潛力與局限，並提出構建「高級記憶模組」的第一版設計方案。

值得注意的是，LibreChat 的 2025 年路線圖中已將「用戶特定記憶 (#5494)」列為計畫中功能，這驗證了我們構想方向的正確性，並為我們的客製化開發提供了潛在的未來兼容性參考。

## 1. LibreChat 現有 RAG 架構：記憶的基石

LibreChat 為實現記憶相關功能提供了所有必要的底層技術，其核心是檢索增強生成 (Retrieval-Augmented Generation, RAG)。

*   **核心組件**：
    *   **Python RAG API (FastAPI)**：負責文件處理、文本切塊、向量嵌入生成、與向量資料庫的交互等。基於 LangChain 實現。
    *   **向量資料庫 (Vector Database)**：
        *   **預設與推薦**：PostgreSQL 及其 `pgvector` 擴充套件。文檔完善，支持高效的相似性搜索和索引 (HNSW, IVFFlat)。
        *   **其他潛在支持**：由於基於 LangChain，理論上可擴展支持其他向量數據庫，如 MongoDB Atlas Vector Search, Meilisearch 等。但這需要額外配置和測試，初期建議使用 pgvector。🏔️土 負責評估。

*   **當前 RAG 功能的工作模式**：
    *   **以「文件為中心」和「對話為界限」**：用戶在某個特定對話中上傳文件，系統對這些文件進行索引。
    *   在該**單次對話的後續交流中**，AI 可以利用這些已索引文件的內容來提供更具上下文的回應。
    *   RAG 的作用域基本限定在當前對話和當前上傳的文件集。

## 2. 現有 RAG 的局限性 (對於長期個性化記憶而言)

雖然 RAG 提供了堅實基礎，但其原生實現對於我們期望的「高級記憶」尚有以下局限：

*   **缺乏跨對話持久性**：記憶不自動跨越不同的對話會話。上次對話中學習到的信息，在新的對話中 AI 可能「忘記」。
*   **非用戶中心/人格中心**：記憶主要與「文件」和「當前對話」關聯，而非與特定的「用戶」或用戶擁有的特定「AI 人格/代理人」長期綁定。
*   **無狀態記憶**：目前的 RAG 更像是一種「無狀態」的上下文增強，它知道當前對話附加了哪些文件，但沒有形成一個關於用戶或 AI 人格的、隨時間演進的、動態的記憶庫。
*   **缺乏記憶管理機制**：缺少對記憶進行分類、賦予重要性、更新、甚至「遺忘」的應用層邏輯。

## 3. 「高級記憶模組」V1 設計方案

為了彌補上述差距，我們需要在 LibreChat 現有架構上進行二次開發，構建一個「高級記憶模組」。V1 設計方案的核心思路是**擴展現有的 Python RAG API**，使其具備更完善的記憶管理能力。

**核心目標**：實現持久化、用戶關聯、人格關聯、可演進的AI記憶。

**3.1. 架構定位：擴展 Python RAG API**

*   **理由**：記憶的本質可以視為一種特殊的、更動態和個性化的 RAG 應用。在現有專為 AI 任務設計的 RAG API (FastAPI + LangChain) 上進行擴展，可以充分利用其已有的向量處理、LLM 交互能力，避免從零開始。
*   **實施**：在 RAG API 項目中創建一個新的服務模組，例如 `memory_manager.py`，專門負責處理所有與高級記憶相關的操作。

**3.2. 擴展向量資料庫 Schema (pgvector)**

這是實現個性化和精細化記憶管理的關鍵。目前 `pgvector` 中存儲的元數據 (metadata) 主要包含 `file_id`。我們必須為「記憶條目」增加更豐富的元數據字段：

*   `memory_id` (UUID): 記憶條目的唯一標識。
*   `user_id` (String): 標識此條記憶屬於哪個用戶。 (🔥火 需與主後端 Node.js 的用戶系統ID對齊)
*   `agent_id` (String, 可選): 標識此條記憶與哪個 AI 人格/代理人相關。若記憶是通用的，則此字段可空。
*   `timestamp_created` (DateTime): 記憶生成的時間。
*   `timestamp_last_accessed` (DateTime): 記憶最近一次被檢索的時間（可用於實現時間衰減）。
*   `memory_type` (String/Enum): 記憶類型，例如：
    *   `CORE_FACT`: 核心事實 (如用戶姓名、職業、重要日期)。
    *   `USER_PREFERENCE`: 用戶偏好 (如喜歡的顏色、溝通風格偏好)。
    *   `CONVERSATION_SUMMARY`: 對話摘要。
    *   `ACTIONABLE_INSIGHT`: 可行動的洞察 (從對話中提取的待辦事項或提醒)。
    *   `RELATIONSHIP_DETAIL`: 關於用戶與他人關係的記憶。
    *   `USER_FEEDBACK`: 用戶的明確反饋或指令。
*   `content` (String): 記憶的文本內容 (用於向量化和展示)。
*   `embedding` (Vector): `content` 的向量嵌入。
*   `importance_score` (Float, 0-1): 記憶的重要性評分，可由 LLM 評估或用戶指定。
*   `access_count` (Integer): 記憶被訪問的次數。
*   `source_conversation_id` (String, 可選): 標識記憶來源於哪個對話。
*   `custom_tags` (Array of Strings, 可選): 用戶或系統自定義的標籤。

**3.3. 實現記憶注入/生成邏輯 (Ingestion Hooks)**

需要在主後端 Node.js 應用中設計並實現觸發記憶生成的鉤子 (Hooks)，並調用擴展後的 RAG API (Memory Manager) 進行記憶存儲。

*   **觸發點示例** (🌱木 負責細化場景)：
    *   **對話結束時 (或定期)**：
        *   觸發一個背景任務。
        *   該任務調用一個專用的「摘要代理人」(LLM) 來總結本次對話的關鍵信息、新發現的事實、用戶情緒等。
        *   將摘要和提取的關鍵點作為記憶條目（可能多條，不同 `memory_type`），存入該用戶的向量空間。
    *   **用戶明確指令時**：
        *   允許用戶通過特定指令 (例如 `/remember "我的生日是10月10日"`) 將某條信息直接存為長期記憶。Node.js 後端解析指令，調用 Memory Manager 存儲。
    *   **用戶個人資料更新時**：
        *   當用戶在個人資料頁面填寫或更新信息（如姓名、職業、興趣等）時，自動將這些信息轉化為 `CORE_FACT` 或 `USER_PREFERENCE` 類型的記憶。
    *   **AI 自主學習/提煉時**：
        *   在對話過程中，AI (LLM) 如果識別到潛在的、值得記憶的新信息，可以生成一個特殊的內部指令，觸發記憶存儲流程。 (較高級，V1 可能不包含)

*   **記憶存儲流程** (🔥火 負責實現)：
    1.  Node.js 後端接收到觸發信號和待記憶內容。
    2.  調用 Python RAG API 中的 Memory Manager 服務接口。
    3.  Memory Manager:
        *   對 `content` 進行預處理（清洗、標準化）。
        *   (可選) 調用 LLM 評估 `importance_score` 和初步分類 `memory_type`。
        *   生成 `content` 的向量嵌入。
        *   將記憶條目（包含所有元數據和嵌入）存入 `pgvector`。

**3.4. 創建記憶檢索層 (Retrieval Layer)**

在每次將用戶提示 (prompt) 發送給 LLM 之前，執行記憶檢索和上下文增強。

*   **檢索觸發**：在 Node.js 主後端，獲取到用戶輸入後，實際請求 LLM 前。
*   **檢索流程** (🔥火 負責實現，🏔️土 協助設計高效查詢)：
    1.  Node.js 後端向 Python RAG API 的 Memory Manager 發起記憶檢索請求。請求參數應包含：
        *   `user_id`
        *   `agent_id` (如果當前 AI 人格明確)
        *   當前用戶的輸入文本 (用於語義搜索)
        *   需要的記憶條數 (e.g., top_k = 5)
        *   (可選) 過濾條件，如 `memory_type`, `timestamp` 範圍等。
    2.  Memory Manager (Python RAG API):
        *   根據用戶輸入文本生成查詢向量。
        *   在 `pgvector` 中執行向量相似性搜索，同時結合元數據進行過濾和排序。
            *   **基礎檢索**：按向量相似度。
            *   **加權檢索策略 (V1.x 或 V2)**：可以設計更複雜的檢索策略，例如結合時間衰減 (最近的記憶更重要)、`importance_score`、`access_count` 等因素進行加權排序。LangChain 的 `SelfQueryRetriever` 或類似機制可能有用。
        *   返回檢索到的 top_k 條記憶內容給 Node.js 後端。

**3.5. 動態提示增強 (Dynamic Prompt Augmentation)**

將檢索到的記憶動態地注入到發送給 LLM 的系統提示 (System Prompt) 或用戶提示的前面。

*   **實施位置**：Node.js 主後端，在組裝最終發送給 LLM 的請求時。
*   **格式化**：將檢索到的記憶條目（可能是 `content` 字段）格式化為易於 LLM 理解的文本。
    *   例如：「請記住以下關於用戶的關鍵信息：\n- [記憶1: 用戶偏好設定為簡潔模式]\n- [記憶2: 用戶上次詢問了關於Python異步編程的問題]\n- [記憶3: 用戶的核心目標是學習如何使用LibreChat]\n...」
*   **注入位置**：
    *   通常注入到 System Prompt 的最前端，使其成為 LLM 行為的基礎上下文。
    *   或者，作為用戶提示的一部分，放在實際用戶問題之前。
    *   (💧水 需要測試不同注入方式對 LLM 回應質量的影響)

## 4. V1 的範圍與未來迭代 (🌱木 🔥火 🏔️土 💧水 共同規劃)

*   **V1 核心功能**：
    *   實現基於 `user_id` 的記憶存儲和檢索。
    *   支持手動指令 `/remember` 觸發記憶。
    *   實現對話結束後的自動摘要記憶（可選 LLM 參與）。
    *   基礎的向量相似度檢索。
    *   動態將檢索到的記憶注入提示。
    *   能夠在 pgvector 中存儲和查詢擴展後的元數據。
*   **V1.x 或 V2 可能的增強功能**：
    *   更複雜的記憶檢索策略（時間衰減、重要性加權、遺忘曲線模擬）。
    *   用戶可視化和管理自己記憶的界面 (🌸Serena 參與設計)。
    *   AI 人格/代理人 (`agent_id`) 級別的記憶隔離與共享。
    *   記憶的自動更新與去重。
    *   LLM 輔助的記憶提煉和結構化 (例如，從多條零散記憶中總結出更高層次的洞察)。
    *   記憶的「遺忘」機制（基於規則或用戶指令）。

## 5. 風險與挑戰

*   **性能**：記憶檢索和LLM摘要步驟不能顯著增加用戶等待時間。🔥火 和 ⚔️金 需關注性能優化。
*   **成本**：如果記憶生成（如對話摘要）頻繁調用 LLM，會增加 Token 成本。⚔️金 需監控。
*   **記憶質量**：如何確保存儲的記憶是準確、相關且無偏見的？如何避免錯誤信息的累積？💧水 需設計驗證策略。
*   **用戶隱私**：記憶數據非常敏感，需要嚴格的權限控制和安全措施。🏔️土 負責安全設計。

**下一步**: 進入 UI/UX 分析 (`../c03_ui_ux_integration_wood_fire/f01_ui_stack_and_branding.md`)。
```
