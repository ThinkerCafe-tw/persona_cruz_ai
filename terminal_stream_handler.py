"""
çµ‚ç«¯ä¸²æµè™•ç†å™¨
æ•æ‰çµ‚ç«¯å°è©±ä¸¦è½‰ç™¼åˆ° AI ç³»çµ±
"""
import sys
import threading
import queue
import time
import logging
from typing import Optional, Callable
from datetime import datetime

logger = logging.getLogger(__name__)

class TerminalStreamHandler:
    """çµ‚ç«¯ä¸²æµè™•ç†å™¨"""
    
    def __init__(self, process_callback: Optional[Callable] = None):
        self.process_callback = process_callback
        self.input_queue = queue.Queue()
        self.output_queue = queue.Queue()
        self.running = False
        self.conversation_log = []
        
    def start(self):
        """é–‹å§‹ç›£è½çµ‚ç«¯è¼¸å…¥è¼¸å‡º"""
        self.running = True
        
        # å•Ÿå‹•è¼¸å…¥ç›£è½åŸ·è¡Œç·’
        input_thread = threading.Thread(target=self._monitor_input, daemon=True)
        input_thread.start()
        
        # å•Ÿå‹•è™•ç†åŸ·è¡Œç·’
        process_thread = threading.Thread(target=self._process_stream, daemon=True)
        process_thread.start()
        
        logger.info("Terminal stream handler started")
        
    def stop(self):
        """åœæ­¢ç›£è½"""
        self.running = False
        logger.info("Terminal stream handler stopped")
        
    def _monitor_input(self):
        """ç›£è½çµ‚ç«¯è¼¸å…¥"""
        while self.running:
            try:
                # é€™æ˜¯ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›å¯¦ä½œéœ€è¦æ›´è¤‡é›œçš„è¼¸å…¥æ•æ‰
                user_input = input()
                if user_input:
                    self.input_queue.put({
                        "type": "user_input",
                        "content": user_input,
                        "timestamp": datetime.now().isoformat()
                    })
            except Exception as e:
                logger.error(f"Input monitoring error: {e}")
                
    def _process_stream(self):
        """è™•ç†ä¸²æµæ•¸æ“š"""
        while self.running:
            try:
                # è™•ç†è¼¸å…¥ä½‡åˆ—
                if not self.input_queue.empty():
                    data = self.input_queue.get()
                    self._handle_stream_data(data)
                    
                # å°å»¶é²é¿å… CPU éè¼‰
                time.sleep(0.1)
                
            except Exception as e:
                logger.error(f"Stream processing error: {e}")
                
    def _handle_stream_data(self, data: dict):
        """è™•ç†ä¸²æµæ•¸æ“š"""
        # è¨˜éŒ„åˆ°å°è©±æ—¥èªŒ
        self.conversation_log.append(data)
        
        # å¦‚æœæœ‰å›èª¿å‡½æ•¸ï¼Œèª¿ç”¨å®ƒ
        if self.process_callback:
            try:
                result = self.process_callback(data)
                if result:
                    self.output_queue.put(result)
            except Exception as e:
                logger.error(f"Callback processing error: {e}")
                
    def get_recent_conversation(self, limit: int = 10) -> list:
        """ç²å–æœ€è¿‘çš„å°è©±è¨˜éŒ„"""
        return self.conversation_log[-limit:]
    
    def clear_log(self):
        """æ¸…é™¤å°è©±è¨˜éŒ„"""
        self.conversation_log.clear()
        

class StreamToAI:
    """ä¸²æµåˆ° AI çš„æ©‹æ¥å™¨"""
    
    def __init__(self, ai_endpoint: Optional[str] = None):
        self.ai_endpoint = ai_endpoint
        self.stream_handler = TerminalStreamHandler(self.process_for_ai)
        self.ai_context = []
        
    def process_for_ai(self, data: dict) -> Optional[dict]:
        """è™•ç†æ•¸æ“šä¸¦ç™¼é€åˆ° AI"""
        # é€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›éœ€è¦é€£æ¥åˆ° Claude/GPT API
        if data["type"] == "user_input":
            # æ§‹å»º AI è«‹æ±‚
            ai_request = {
                "role": "user",
                "content": data["content"],
                "timestamp": data["timestamp"]
            }
            
            # åŠ å…¥ä¸Šä¸‹æ–‡
            self.ai_context.append(ai_request)
            
            # é€™è£¡æ‡‰è©²èª¿ç”¨å¯¦éš›çš„ AI API
            # response = self.call_ai_api(self.ai_context)
            
            # æ¨¡æ“¬ AI å›æ‡‰
            ai_response = {
                "role": "assistant",
                "content": f"CRUZ: æ”¶åˆ°ä½ èªªçš„ '{data['content']}'",
                "timestamp": datetime.now().isoformat()
            }
            
            self.ai_context.append(ai_response)
            
            return ai_response
            
        return None
    
    def start_streaming(self):
        """é–‹å§‹ä¸²æµ"""
        self.stream_handler.start()
        print("ğŸ¯ CRUZ çµ‚ç«¯ä¸²æµå·²å•Ÿå‹•...")
        print("ï¼ˆé€™æ˜¯åŸå‹ç‰ˆæœ¬ï¼Œå®Œæ•´åŠŸèƒ½éœ€è¦æ•´åˆ APIï¼‰")
        
    def stop_streaming(self):
        """åœæ­¢ä¸²æµ"""
        self.stream_handler.stop()
        

# ç°¡å–®çš„ç¤ºç¯„ç¨‹å¼
if __name__ == "__main__":
    print("=== çµ‚ç«¯ä¸²æµè™•ç†å™¨ç¤ºç¯„ ===")
    print("é€™æ˜¯ä¸€å€‹æ¦‚å¿µé©—è­‰ï¼Œå±•ç¤ºå¦‚ä½•æ•æ‰çµ‚ç«¯å°è©±")
    print("å¯¦éš›å¯¦ä½œéœ€è¦ï¼š")
    print("1. æ•´åˆå¯¦éš›çš„ Claude/GPT API")
    print("2. å¯¦ä½œèªéŸ³è½‰æ›ï¼ˆTTS/STTï¼‰")
    print("3. æ›´è¤‡é›œçš„è¼¸å…¥è¼¸å‡ºæ•æ‰æ©Ÿåˆ¶")
    print("\nè¼¸å…¥ 'quit' çµæŸç¨‹å¼\n")
    
    # å‰µå»ºä¸²æµè™•ç†å™¨
    stream_to_ai = StreamToAI()
    
    # è‡ªè¨‚è™•ç†å‡½æ•¸
    def custom_processor(data):
        if data["type"] == "user_input":
            content = data["content"]
            if content.lower() == "quit":
                stream_to_ai.stop_streaming()
                print("å†è¦‹ï¼")
                sys.exit(0)
            else:
                # é€™è£¡å¯ä»¥åŠ å…¥ CRUZ é–‹ç™¼è€…æ¨¡å¼çš„æ•´åˆ
                print(f"[è™•ç†ä¸­] {content}")
                return {
                    "type": "ai_response",
                    "content": f"æˆ‘ç†è§£äº†ï¼š{content}",
                    "timestamp": datetime.now().isoformat()
                }
    
    # è¨­ç½®è‡ªè¨‚è™•ç†å™¨
    stream_to_ai.stream_handler.process_callback = custom_processor
    
    # é–‹å§‹ä¸²æµ
    try:
        stream_to_ai.start_streaming()
        
        # ä¿æŒç¨‹å¼é‹è¡Œ
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\nç¨‹å¼ä¸­æ–·")
        stream_to_ai.stop_streaming()