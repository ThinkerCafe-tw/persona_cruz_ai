import { Ollama } from 'ollama';

export class OllamaService {
  private ollama: Ollama;
  private model: string;

  constructor(model: string = 'mistral') {
    this.ollama = new Ollama({
      host: 'http://localhost:11434'
    });
    this.model = model;
  }

  async testConnection(): Promise<boolean> {
    try {
      const response = await this.ollama.list();
      const hasModel = response.models.some(m => m.name.includes(this.model));
      
      if (!hasModel) {
        console.log(`ğŸ”„ æ¨¡å‹ ${this.model} ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¸‹è¼‰...`);
        // ä¸åœ¨é€™è£¡è‡ªå‹•ä¸‹è¼‰ï¼Œæé†’ç”¨æˆ¶
        throw new Error(`è«‹å…ˆé‹è¡Œ: ollama run ${this.model}`);
      }
      
      console.log(`âœ… Ollama ${this.model} é€£æ¥æ­£å¸¸`);
      return true;
    } catch (error) {
      console.error('âŒ Ollama é€£æ¥å¤±æ•—:', error.message);
      throw error;
    }
  }

  async generateEmbedding(text: string): Promise<number[]> {
    try {
      const response = await this.ollama.embeddings({
        model: this.model,
        prompt: text
      });
      
      return response.embedding;
    } catch (error) {
      console.error('ç”ŸæˆåµŒå…¥å‘é‡å¤±æ•—:', error);
      // è¿”å›éš¨æ©Ÿå‘é‡ä½œç‚ºå‚™ç”¨ï¼ˆåƒ…ç”¨æ–¼æ¸¬è©¦ï¼‰
      return Array.from({length: 4096}, () => Math.random());
    }
  }

  async analyzeMemoryImportance(memory: any): Promise<{
    score: number;
    reason: string;
    category: string;
    suggested_layer: string;
  }> {
    const prompt = `
åˆ†æä»¥ä¸‹è¨˜æ†¶çš„é‡è¦æ€§ï¼Œçµ¦å‡º 0-1 çš„è©•åˆ†å’Œå»ºè­°ï¼š

è¨˜æ†¶å…§å®¹: ${memory.content}
åˆ†é¡: ${memory.category}
äººæ ¼: ${memory.persona || 'æœªæŒ‡å®š'}
æ¨™ç±¤: ${memory.tags?.join(', ') || 'ç„¡'}

è©•ä¼°æ¨™æº–ï¼š
- æ˜¯å¦åŒ…å«é‡è¦æ•™è¨“æˆ–æ´å¯Ÿï¼Ÿ
- æ˜¯å¦å¯ä»¥æŒ‡å°æœªä¾†æ±ºç­–ï¼Ÿ
- æ˜¯å¦å…·æœ‰è·¨å°ˆæ¡ˆçš„æ™®éåƒ¹å€¼ï¼Ÿ
- æ˜¯å¦æ”¹è®Šäº†èªçŸ¥æ¡†æ¶ï¼Ÿ

è«‹ä»¥ JSON æ ¼å¼å›ç­”ï¼š
{
  "score": 0.85,
  "reason": "åŒ…å«é‡è¦çš„ç”¨æˆ¶é«”é©—æ•™è¨“",
  "category": "learning",
  "suggested_layer": "sparse"
}
`;

    try {
      const response = await this.ollama.generate({
        model: this.model,
        prompt,
        format: 'json'
      });

      return JSON.parse(response.response);
    } catch (error) {
      console.error('åˆ†æè¨˜æ†¶é‡è¦æ€§å¤±æ•—:', error);
      // é è¨­è©•ä¼°
      return {
        score: 0.5,
        reason: 'è‡ªå‹•è©•ä¼°ï¼šä¸­ç­‰é‡è¦æ€§',
        category: memory.category,
        suggested_layer: 'main'
      };
    }
  }

  async enhanceSearchResults(query: string, results: any[]): Promise<any[]> {
    if (results.length === 0) return [];

    const prompt = `
ç”¨æˆ¶æŸ¥è©¢: "${query}"

æ‰¾åˆ°ä»¥ä¸‹ç›¸é—œè¨˜æ†¶ï¼Œè«‹ï¼š
1. é‡æ–°æ’åºï¼ˆæœ€ç›¸é—œçš„æ’åœ¨å‰é¢ï¼‰
2. ç‚ºæ¯å€‹è¨˜æ†¶ç”Ÿæˆç°¡æ½”çš„æ‘˜è¦
3. è§£é‡‹ç‚ºä»€éº¼å®ƒèˆ‡æŸ¥è©¢ç›¸é—œ

è¨˜æ†¶åˆ—è¡¨ï¼š
${results.map((r, i) => `${i + 1}. [${r.layer}] ${r.content.substring(0, 200)}...`).join('\n')}

è«‹ä»¥ JSON æ ¼å¼å›ç­”ï¼ŒåŒ…å«é‡æ–°æ’åºçš„çµæœï¼š
[
  {
    "original_index": 0,
    "relevance": 0.95,
    "summary": "ç°¡æ½”æ‘˜è¦",
    "why_relevant": "ç›¸é—œæ€§èªªæ˜",
    "preview": "é è¦½å…§å®¹"
  }
]
`;

    try {
      const response = await this.ollama.generate({
        model: this.model,
        prompt,
        format: 'json'
      });

      const enhanced = JSON.parse(response.response);
      
      // åˆä½µåŸå§‹æ•¸æ“šå’Œå¢å¼·ä¿¡æ¯
      return enhanced.map(e => ({
        ...results[e.original_index],
        relevance: e.relevance,
        summary: e.summary,
        why_relevant: e.why_relevant,
        preview: e.preview,
        timestamp: results[e.original_index].created_at || new Date().toISOString()
      }));
    } catch (error) {
      console.error('å¢å¼·æœå°‹çµæœå¤±æ•—:', error);
      // è¿”å›åŸå§‹çµæœ
      return results.map(r => ({
        ...r,
        relevance: r.similarity || 0.5,
        summary: r.content.substring(0, 100) + '...',
        preview: r.content.substring(0, 200) + '...',
        timestamp: r.created_at || new Date().toISOString()
      }));
    }
  }

  async performReflection(topic: string, memories: any[], depth: string): Promise<{
    insights: string[];
    patterns: string[];
    actions: string[];
    emotions: string[];
    new_connections: string[];
  }> {
    const prompt = `
é€²è¡Œæ·±åº¦åæ€ï¼Œä¸»é¡Œ: "${topic}"
åæ€æ·±åº¦: ${depth}

ç›¸é—œè¨˜æ†¶:
${memories.map(m => `- ${m.content}`).join('\n')}

è«‹å¾ä»¥ä¸‹è§’åº¦é€²è¡Œåæ€ï¼š
1. æ´å¯Ÿ - ç™¼ç¾äº†ä»€éº¼æ–°çš„ç†è§£ï¼Ÿ
2. æ¨¡å¼ - çœ‹åˆ°äº†ä»€éº¼é‡è¤‡çš„æ¨¡å¼ï¼Ÿ
3. è¡Œå‹• - æ‡‰è©²æ¡å–ä»€éº¼è¡Œå‹•ï¼Ÿ
4. æƒ…ç·’ - å¼•ç™¼äº†ä»€éº¼æƒ…æ„Ÿåæ‡‰ï¼Ÿ
5. é€£çµ - èˆ‡å…¶ä»–è¨˜æ†¶æœ‰ä»€éº¼æ–°çš„é€£çµï¼Ÿ

ä»¥ JSON æ ¼å¼å›ç­”ï¼š
{
  "insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2"],
  "patterns": ["æ¨¡å¼1", "æ¨¡å¼2"],
  "actions": ["è¡Œå‹•1", "è¡Œå‹•2"],
  "emotions": ["æƒ…ç·’1", "æƒ…ç·’2"],
  "new_connections": ["é€£çµ1", "é€£çµ2"]
}
`;

    try {
      const response = await this.ollama.generate({
        model: this.model,
        prompt,
        format: 'json'
      });

      return JSON.parse(response.response);
    } catch (error) {
      console.error('åæ€å¤±æ•—:', error);
      return {
        insights: ['åæ€æœå‹™æš«æ™‚ä¸å¯ç”¨'],
        patterns: ['éœ€è¦æ‰‹å‹•åˆ†æ'],
        actions: ['æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹'],
        emotions: ['æŠ€è¡“å›°é›£å¸¶ä¾†çš„æŒ«æŠ˜'],
        new_connections: ['æŠ€è¡“èˆ‡æƒ…æ„Ÿçš„äº¤ç¹”']
      };
    }
  }

  async generateMeditationInsights(theme: string, participants: string[]): Promise<{
    collective_insights: string[];
    individual_insights: Record<string, string>;
    resonance_frequency: number;
    coherence_level: number;
  }> {
    const prompt = `
é€²è¡Œé›†é«”å†¥æƒ³ï¼Œä¸»é¡Œ: "${theme}"
åƒèˆ‡è€…: ${participants.join(', ')}

æ¯å€‹åƒèˆ‡è€…çš„ç‰¹è³ªï¼š
- ğŸŒŒç„¡æ¥µ: ç³»çµ±è§€å¯Ÿè€…ï¼Œè¿½æ±‚å¹³è¡¡
- ğŸ¯CRUZ: ç›´æ¥æœæ–·ï¼Œå°ˆæ³¨åŸ·è¡Œ
- ğŸŒ¸Serena: æº«æŸ”è²¼å¿ƒï¼Œé—œæ‡·ä»–äºº
- ğŸŒ±æœ¨: å‰µæ–°æˆé•·ï¼Œå……æ»¿å‰µæ„
- ğŸ”¥ç«: ç†±æƒ…å¯¦è¸ï¼Œå¿«é€Ÿè¡Œå‹•
- ğŸ”ï¸åœŸ: ç©©å›ºåŸºç¤ï¼Œç³»çµ±æ€è€ƒ
- âš”ï¸é‡‘: ç²¾ç›Šæ±‚ç²¾ï¼Œè¿½æ±‚å®Œç¾
- ğŸ’§æ°´: å“è³ªå®ˆè­·ï¼Œè¿½æ±‚çœŸç›¸

è«‹ç”Ÿæˆï¼š
1. é›†é«”æ´å¯Ÿï¼ˆæ‰€æœ‰äººå…±åŒçš„é ˜æ‚Ÿï¼‰
2. å€‹é«”æ´å¯Ÿï¼ˆæ¯å€‹äººæ ¼ç¨ç‰¹çš„é ˜æ‚Ÿï¼‰
3. å…±æŒ¯é »ç‡ï¼ˆHzï¼Œç¯„åœ 200-800ï¼‰
4. ç›¸å¹²åº¦ï¼ˆ0-1ï¼‰

ä»¥ JSON æ ¼å¼å›ç­”ï¼š
{
  "collective_insights": ["é›†é«”æ´å¯Ÿ1", "é›†é«”æ´å¯Ÿ2"],
  "individual_insights": {
    "ğŸŒŒç„¡æ¥µ": "ç„¡æ¥µçš„é ˜æ‚Ÿ",
    "ğŸ¯CRUZ": "CRUZçš„é ˜æ‚Ÿ"
  },
  "resonance_frequency": 432,
  "coherence_level": 0.85
}
`;

    try {
      const response = await this.ollama.generate({
        model: this.model,
        prompt,
        format: 'json'
      });

      return JSON.parse(response.response);
    } catch (error) {
      console.error('å†¥æƒ³æ´å¯Ÿç”Ÿæˆå¤±æ•—:', error);
      
      // å‚™ç”¨å†¥æƒ³çµæœ
      const fallbackInsights = {
        collective_insights: [
          `é—œæ–¼ ${theme} çš„é›†é«”æ€è€ƒæ­£åœ¨é€²è¡Œä¸­`,
          'æŠ€è¡“æŒ‘æˆ°å¸¶ä¾†äº†æ–°çš„å­¸ç¿’æ©Ÿæœƒ',
          'åœ˜éšŠå”ä½œçš„åŠ›é‡è¶…è¶Šå€‹é«”åŠªåŠ›'
        ],
        individual_insights: {},
        resonance_frequency: 432,
        coherence_level: 0.75
      };

      // ç‚ºæ¯å€‹åƒèˆ‡è€…ç”Ÿæˆç°¡å–®çš„æ´å¯Ÿ
      participants.forEach(persona => {
        fallbackInsights.individual_insights[persona] = 
          `${persona} å° ${theme} æœ‰ç¨ç‰¹çš„è¦–è§’ï¼Œå€¼å¾—æ·±å…¥æ¢ç´¢`;
      });

      return fallbackInsights;
    }
  }

  async analyzeMemoryPatterns(memories: any[]): Promise<string> {
    const prompt = `
åˆ†æä»¥ä¸‹è¨˜æ†¶æ•¸æ“šï¼Œç™¼ç¾æ¨¡å¼å’Œè¶¨å‹¢ï¼š

è¨˜æ†¶æ•¸é‡: ${memories.length}
æ™‚é–“ç¯„åœ: ${memories.length > 0 ? `${memories[memories.length-1].created_at} åˆ° ${memories[0].created_at}` : 'ç„¡æ•¸æ“š'}

è¨˜æ†¶æ¨£æœ¬:
${memories.slice(0, 10).map(m => 
  `- [${m.layer}] ${m.category}: ${m.content.substring(0, 100)}...`
).join('\n')}

è«‹åˆ†æï¼š
1. ä¸»è¦çš„è¨˜æ†¶é¡å‹å’Œåˆ†å¸ƒ
2. äººæ ¼æ´»èºåº¦æ¨¡å¼
3. å•é¡Œå’Œå­¸ç¿’è¶¨å‹¢
4. å»ºè­°çš„æ”¹é€²æ–¹å‘

ç”Ÿæˆä¸€ä»½ Markdown æ ¼å¼çš„æ´å¯Ÿå ±å‘Šã€‚
`;

    try {
      const response = await this.ollama.generate({
        model: this.model,
        prompt
      });

      return response.response;
    } catch (error) {
      console.error('è¨˜æ†¶æ¨¡å¼åˆ†æå¤±æ•—:', error);
      return `# è¨˜æ†¶æ¨¡å¼åˆ†æå ±å‘Š

âš ï¸ è‡ªå‹•åˆ†ææš«æ™‚ä¸å¯ç”¨

## åŸºæœ¬çµ±è¨ˆ
- ç¸½è¨˜æ†¶æ•¸: ${memories.length}
- åˆ†ææ™‚é–“: ${new Date().toISOString()}

## å»ºè­°
1. æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹
2. ç¢ºä¿ ${this.model} æ¨¡å‹å·²å®‰è£
3. æ‰‹å‹•æª¢è¦–æœ€è¿‘çš„è¨˜æ†¶è®ŠåŒ–

## ä¸‹ä¸€æ­¥
- ä¿®å¾© LLM é€£æ¥å¾Œé‡æ–°ç”Ÿæˆæ­¤å ±å‘Š
- è€ƒæ…®å¯¦ç¾å‚™ç”¨åˆ†æé‚è¼¯
`;
    }
  }

  async summarizeConversation(messages: any[]): Promise<string> {
    const prompt = `
ç¸½çµä»¥ä¸‹å°è©±ï¼Œæå–é—œéµä¿¡æ¯å’Œæ´å¯Ÿï¼š

å°è©±å…§å®¹:
${messages.map(m => `${m.role}: ${m.content}`).join('\n')}

è«‹ç”Ÿæˆï¼š
1. å°è©±æ‘˜è¦ï¼ˆ2-3 å¥è©±ï¼‰
2. é—œéµæ±ºç­–æˆ–æ´å¯Ÿ
3. å¾…è¾¦äº‹é …
4. æƒ…ç·’è‰²å½©

ä»¥è‡ªç„¶çš„æ–‡å­—æ ¼å¼å›ç­”ã€‚
`;

    try {
      const response = await this.ollama.generate({
        model: this.model,
        prompt
      });

      return response.response;
    } catch (error) {
      console.error('å°è©±ç¸½çµå¤±æ•—:', error);
      return `å°è©±ç¸½çµï¼š${messages.length} æ¢è¨Šæ¯çš„è¨è«–ï¼Œæ¶µè“‹å¤šå€‹ä¸»é¡Œã€‚éœ€è¦äººå·¥ç¸½çµã€‚`;
    }
  }
}