#!/usr/bin/env python3
"""
CRUZ äººæ ¼ä»£ç†æœå‹™ - ç°¡åŒ–ç‰ˆæœ¬
ç‚º LibreChat æä¾› OpenAI å…¼å®¹çš„ API
"""
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import asyncio
import json
import os
import sys

# å°å…¥ç¾æœ‰çš„ CRUZ ç³»çµ±
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å˜—è©¦å°å…¥ CRUZ ç³»çµ±ï¼Œå¦‚æœå¤±æ•—å‰‡ä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬
try:
    from cruz_chatbot import CruzChatbot
    from emotion_engine import cruz_emotion, EmotionTrigger
    CRUZ_AVAILABLE = True
except ImportError:
    print("âš ï¸ CRUZ æ¨¡çµ„æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬")
    CRUZ_AVAILABLE = False

app = FastAPI(title="CRUZ Persona Proxy", version="1.0.0")

# æ·»åŠ  CORS ä¸­é–“ä»¶è§£æ±ºç€è¦½å™¨è·¨åŸŸå•é¡Œ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è¨±æ‰€æœ‰ä¾†æº
    allow_credentials=True,
    allow_methods=["*"],  # å…è¨±æ‰€æœ‰æ–¹æ³•
    allow_headers=["*"],  # å…è¨±æ‰€æœ‰ headers
)

# è«‹æ±‚æ¨¡å‹
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatCompletionRequest(BaseModel):
    model: str
    messages: List[ChatMessage]
    temperature: Optional[float] = 0.8
    max_tokens: Optional[int] = 4096
    stream: Optional[bool] = False

# åˆå§‹åŒ– CRUZ (å¦‚æœå¯ç”¨)
cruz_bot = None
if CRUZ_AVAILABLE:
    try:
        cruz_bot = CruzChatbot()
        print("âœ… CRUZ èŠå¤©æ©Ÿå™¨äººå·²åˆå§‹åŒ–")
    except Exception as e:
        print(f"âš ï¸ CRUZ åˆå§‹åŒ–å¤±æ•—: {e}")
        CRUZ_AVAILABLE = False

@app.get("/")
async def root():
    return {
        "message": "ğŸ¯ CRUZ Persona Proxy Server",
        "version": "1.0.0",
        "status": "ready"
    }

@app.get("/v1/models")
async def list_models():
    """åˆ—å‡ºå¯ç”¨çš„äººæ ¼æ¨¡å‹"""
    return {
        "object": "list",
        "data": [
            {
                "id": "cruz-decisive",
                "object": "model",
                "created": 1677610602,
                "owned_by": "cruz-ai",
                "display_name": "ğŸ¯ CRUZ - Decisive Action AI"
            },
            {
                "id": "serena-supportive", 
                "object": "model",
                "created": 1677610602,
                "owned_by": "cruz-ai",
                "display_name": "ğŸŒ¸ Serena - Supportive AI"
            }
        ]
    }

@app.post("/v1/chat/completions")
async def chat_completions(request: ChatCompletionRequest):
    """è™•ç†èŠå¤©å®Œæˆè«‹æ±‚"""
    try:
        # æå–æœ€å¾Œçš„ç”¨æˆ¶è¨Šæ¯
        user_message = ""
        for msg in reversed(request.messages):
            if msg.role == "user":
                user_message = msg.content
                break
        
        if not user_message:
            raise HTTPException(status_code=400, detail="No user message found")
        
        # æ ¹æ“šæ¨¡å‹é¸æ“‡äººæ ¼
        if request.model == "cruz-decisive":
            if CRUZ_AVAILABLE and cruz_bot:
                # ä½¿ç”¨çœŸå¯¦çš„ CRUZ äººæ ¼
                response_text = await cruz_bot.generate_response(user_message)
            else:
                # ä½¿ç”¨æ¨¡æ“¬çš„ CRUZ å›æ‡‰
                response_text = f"ğŸ¯ {user_message}? åœæ­¢åˆ†æï¼Œé–‹å§‹è¡Œå‹•ï¼æ™‚é–“å°±æ˜¯é‡‘éŒ¢ï¼Œæ•ˆç‡å°±æ˜¯ç”Ÿå‘½ï¼ç›´æ¥æ‰¾è§£æ±ºæ–¹æ¡ˆï¼Œä¸è¦æ‹–å»¶ï¼"
        elif request.model == "serena-supportive":
            # ç°¡åŒ–çš„ Serena å›æ‡‰  
            response_text = f"ğŸŒ¸ æˆ‘ç†è§£ä½ çš„æ„Ÿå—ã€‚é—œæ–¼ã€Œ{user_message[:50]}...ã€é€™å€‹å•é¡Œï¼Œè®“æˆ‘å€‘ä¸€èµ·æ…¢æ…¢è™•ç†ã€‚æˆ‘æœƒé™ªä¼´ä½ æ‰¾åˆ°æœ€å¥½çš„è§£æ±ºæ–¹æ³•ã€‚"
        else:
            # é è¨­ä½¿ç”¨ CRUZ é¢¨æ ¼
            if CRUZ_AVAILABLE and cruz_bot:
                response_text = await cruz_bot.generate_response(user_message)
            else:
                response_text = f"ğŸ¯ æ”¶åˆ°ï¼é—œæ–¼ã€Œ{user_message[:30]}...ã€- æˆ‘çš„å»ºè­°æ˜¯ï¼šç«‹å³åˆ¶å®šè¡Œå‹•è¨ˆåŠƒï¼Œåˆ†è§£æˆå…·é«”æ­¥é©Ÿï¼Œç„¶å¾ŒåŸ·è¡Œï¼"
        
        # å›å‚³ OpenAI æ ¼å¼çš„å›æ‡‰
        return JSONResponse(content={
            "id": f"chatcmpl-{generate_id()}",
            "object": "chat.completion", 
            "created": int(asyncio.get_event_loop().time()),
            "model": request.model,
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": response_text
                },
                "finish_reason": "stop"
            }],
            "usage": {
                "prompt_tokens": len(user_message.split()),
                "completion_tokens": len(response_text.split()),
                "total_tokens": len(user_message.split()) + len(response_text.split())
            }
        })
        
    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    if CRUZ_AVAILABLE and 'cruz_emotion' in globals():
        try:
            emotion_status = cruz_emotion.get_status()
            current_emotion = emotion_status["current_state"]
        except:
            current_emotion = "determined"
    else:
        current_emotion = "ready"
    
    return {
        "status": "healthy",
        "cruz_system": "available" if CRUZ_AVAILABLE else "simplified",
        "cruz_emotion": current_emotion,
        "models_available": ["cruz-decisive", "serena-supportive"]
    }

def generate_id() -> str:
    """ç”Ÿæˆå”¯ä¸€ ID"""
    import random
    import string
    return ''.join(random.choices(string.ascii_letters + string.digits, k=16))

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ Starting CRUZ Persona Proxy Server...")
    print("ğŸ“ æœå‹™ç«¯é»: http://localhost:8001")
    print("ğŸ¯ CRUZ å·²å°±ç·’ï¼Œå¯ä»¥é–‹å§‹å°è©±ï¼")
    uvicorn.run(app, host="0.0.0.0", port=8001)