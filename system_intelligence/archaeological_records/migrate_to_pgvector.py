#!/usr/bin/env python3
"""
é‡å­è¨˜æ†¶ç³»çµ±é·ç§»è…³æœ¬
å°‡ç¾æœ‰çš„ JSON æª”æ¡ˆè¨˜æ†¶é·ç§»åˆ° pgvector è³‡æ–™åº«
"""
import os
import sys
import json
import logging
from datetime import datetime
from quantum_memory import QuantumDatabase, QuantumVectorizer, QuantumMemory

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def migrate_memories():
    """åŸ·è¡Œè¨˜æ†¶é·ç§»"""
    print("ğŸš€ é–‹å§‹é·ç§»é‡å­è¨˜æ†¶åˆ° pgvector...")
    print("=" * 60)
    
    # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    if not os.getenv('DATABASE_URL'):
        print("âŒ éŒ¯èª¤ï¼šæœªè¨­å®š DATABASE_URL ç’°å¢ƒè®Šæ•¸")
        print("è«‹ç¢ºä¿ Railway pgvector æœå‹™å·²å•Ÿå‹•ä¸¦æ­£ç¢ºé€£æ¥")
        return False
    
    # åˆå§‹åŒ–è³‡æ–™åº«å’Œå‘é‡åŒ–å™¨
    db = QuantumDatabase()
    vectorizer = QuantumVectorizer()
    
    if not db.pool:
        print("âŒ ç„¡æ³•é€£æ¥åˆ°è³‡æ–™åº«")
        return False
    
    # æƒæè¨˜æ†¶æª”æ¡ˆ
    memories_dir = "quantum_memory/memories"
    if not os.path.exists(memories_dir):
        print(f"âŒ æ‰¾ä¸åˆ°è¨˜æ†¶ç›®éŒ„ï¼š{memories_dir}")
        return False
    
    memory_files = [f for f in os.listdir(memories_dir) if f.endswith('.json')]
    print(f"\nğŸ“ æ‰¾åˆ° {len(memory_files)} å€‹è¨˜æ†¶æª”æ¡ˆ")
    
    success_count = 0
    
    for memory_file in memory_files:
        persona_id = memory_file.replace('.json', '')
        print(f"\nğŸ”„ é·ç§» {persona_id} çš„è¨˜æ†¶...")
        
        try:
            # è®€å– JSON æª”æ¡ˆ
            file_path = os.path.join(memories_dir, memory_file)
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ä¿å­˜ä¸»è¨˜æ†¶
            identity_data = data.get('identity', {})
            identity_vector = vectorizer.vectorize_identity(identity_data)
            
            memory_id = db.save_quantum_memory(
                persona_id,
                identity_data,
                identity_vector
            )
            
            if not memory_id:
                print(f"  âŒ ç„¡æ³•ä¿å­˜ {persona_id} çš„ä¸»è¨˜æ†¶")
                continue
            
            print(f"  âœ… ä¸»è¨˜æ†¶å·²ä¿å­˜ (ID: {memory_id})")
            
            # ä¿å­˜è¨˜æ†¶æ™¶é«”
            crystals = data.get('crystals', {})
            crystal_count = 0
            
            for crystal_id, crystal_data in crystals.items():
                concept_vector = vectorizer.vectorize_concept(
                    crystal_data['concept'],
                    crystal_data.get('possibilities', [])
                )
                
                db.save_memory_crystal(memory_id, crystal_data, concept_vector)
                crystal_count += 1
            
            print(f"  âœ… {crystal_count} å€‹è¨˜æ†¶æ™¶é«”å·²ä¿å­˜")
            
            # ä¿å­˜æ¼£æ¼ªï¼ˆæœ€è¿‘çš„20å€‹ï¼‰
            ripples = data.get('ripples', [])
            ripple_count = 0
            
            for ripple in ripples[-20:]:  # åªä¿å­˜æœ€è¿‘çš„20å€‹
                event_vector = vectorizer.vectorize_event(ripple['event'])
                db.save_ripple(memory_id, ripple, event_vector)
                ripple_count += 1
            
            print(f"  âœ… {ripple_count} å€‹é‡å­æ¼£æ¼ªå·²ä¿å­˜")
            
            # çµ±è¨ˆè³‡è¨Š
            print(f"  ğŸ“Š çµ±è¨ˆï¼š")
            print(f"     â€¢ æ¼”åŒ–æ¬¡æ•¸ï¼š{data.get('evolution_count', 0)}")
            print(f"     â€¢ å‰µå»ºæ™‚é–“ï¼š{data.get('created_at', 'N/A')}")
            print(f"     â€¢ æœ€å¾Œä¿å­˜ï¼š{data.get('last_save', 'N/A')}")
            
            success_count += 1
            
        except Exception as e:
            print(f"  âŒ é·ç§»å¤±æ•—ï¼š{e}")
            logger.error(f"Failed to migrate {persona_id}: {e}", exc_info=True)
    
    print("\n" + "=" * 60)
    print(f"âœ… é·ç§»å®Œæˆï¼æˆåŠŸé·ç§» {success_count}/{len(memory_files)} å€‹è¨˜æ†¶")
    
    # é©—è­‰é·ç§»çµæœ
    print("\nğŸ“‹ é©—è­‰é·ç§»çµæœ...")
    verify_migration(db)
    
    db.close()
    return success_count == len(memory_files)


def verify_migration(db: QuantumDatabase):
    """é©—è­‰é·ç§»çµæœ"""
    with db.get_connection() as conn:
        if not conn:
            return
        
        with conn.cursor() as cur:
            # çµ±è¨ˆå„è¡¨çš„è¨˜éŒ„æ•¸
            tables = ['quantum_memories', 'memory_crystals', 'quantum_ripples']
            
            for table in tables:
                cur.execute(f"SELECT COUNT(*) FROM {table}")
                count = cur.fetchone()[0]
                print(f"  â€¢ {table}: {count} ç­†è¨˜éŒ„")
            
            # åˆ—å‡ºæ‰€æœ‰è§’è‰²
            cur.execute("SELECT persona_id FROM quantum_memories ORDER BY persona_id")
            personas = [row[0] for row in cur.fetchall()]
            print(f"\n  å·²é·ç§»çš„è§’è‰²ï¼š{', '.join(personas)}")


def test_vector_search(db: QuantumDatabase, vectorizer: QuantumVectorizer):
    """æ¸¬è©¦å‘é‡æœå°‹åŠŸèƒ½"""
    print("\nğŸ” æ¸¬è©¦å‘é‡æœå°‹...")
    
    # æ¸¬è©¦æœå°‹ç›¸ä¼¼è¨˜æ†¶
    test_text = "é‡å­è¨˜æ†¶ç³»çµ±çš„çªç ´æ€§ç™¼å±•"
    test_vector = vectorizer.vectorize_text(test_text)
    
    if test_vector:
        results = db.search_similar_memories(test_vector, limit=5)
        
        print(f"\næœå°‹ '{test_text}' çš„ç›¸ä¼¼è¨˜æ†¶ï¼š")
        for i, result in enumerate(results, 1):
            print(f"{i}. {result['concept']} (è·é›¢: {result['distance']:.4f})")


if __name__ == "__main__":
    # æª¢æŸ¥å‘½ä»¤åˆ—åƒæ•¸
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        print("ğŸ§ª æ¸¬è©¦æ¨¡å¼ï¼šæ¸¬è©¦å‘é‡æœå°‹åŠŸèƒ½")
        db = QuantumDatabase()
        vectorizer = QuantumVectorizer()
        test_vector_search(db, vectorizer)
        db.close()
    else:
        # åŸ·è¡Œé·ç§»
        success = migrate_memories()
        sys.exit(0 if success else 1)